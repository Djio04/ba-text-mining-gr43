{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/iliamarkov/work/VU-TM-2022-changes/ba-text-mining/Lab1-apple-samsung-example.txt\n",
      "does path exist? -> False\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print(path_to_file)\n",
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = []\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_id = 1\n",
    "print('SENTENCE', sentences_nltk[sent_id])\n",
    "print('TOKENS', tokens_per_sentence[sent_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_tags_per_sentence = []\n",
    "for tokens in tokens_per_sentence:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_per_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_output_per_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constituency_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {}             # ???''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_v2_output_per_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constituency_v2_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text) # insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 3] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
    "\n",
    "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
    "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
    "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK (POS TAGGING)</th>\n",
       "      <th>SpaCy (TOKEN.TAG)</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Documents', 'NNS'),</td>\n",
       "      <td>Documents: NNPS (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('filed', 'VBN'),</td>\n",
       "      <td>filed: VBD (VERB)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>* every instance where i noticed the use of the IN tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('to', 'TO'),</td>\n",
       "      <td>to: IN (ADP)</td>\n",
       "      <td>NLTK just tags to as TO, but SpaCy uses IN to tag preposition or subordinating conjunction (e.g., \"to\", \"in\", \"on\")*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('the', 'DT'),</td>\n",
       "      <td>the: DT (DET)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPACY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('San', 'NNP'),</td>\n",
       "      <td>San: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Named Entities, Phrases, and Concepts:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('Jose', 'NNP'),</td>\n",
       "      <td>Jose: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Jose: GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('federal', 'JJ'),</td>\n",
       "      <td>federal: JJ (ADJ)\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California: GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('court', 'NN'),</td>\n",
       "      <td>court: NN (NOUN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November 23: DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('in', 'IN'),</td>\n",
       "      <td>in: IN (ADP)</td>\n",
       "      <td>NLTK has a seperate IN tag, where SpaCy uses the IN tag for multiple words*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>six: CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('California', 'NNP'),</td>\n",
       "      <td>California: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samsung: ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('on', 'IN'),</td>\n",
       "      <td>on: IN (ADP)</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jelly Bean: WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('November', 'NNP'),</td>\n",
       "      <td>November: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple: ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('23', 'CD'),</td>\n",
       "      <td>23: CD (NUM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('list', 'NN'),</td>\n",
       "      <td>list: NN (NOUN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('six', 'CD'),</td>\n",
       "      <td>six: CD (NUM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('Samsung', 'NNP'),</td>\n",
       "      <td>Samsung: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('products', 'NNS'),</td>\n",
       "      <td>products: NNS (NOUN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('running', 'VBG'),</td>\n",
       "      <td>running: VBG (VERB)\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ORGANIZATION San/NNP Jose/NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('the', 'DT'),</td>\n",
       "      <td>the: DT (DET)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(GPE California/NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('``', '``'),</td>\n",
       "      <td>\": `` (PUNCT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ORGANIZATION Samsung/NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>('Jelly', 'RB'),</td>\n",
       "      <td>Jelly: NNP (PROPN)</td>\n",
       "      <td>NLTK tags jelly as an adverb, SpaCy tags it as proper noun singular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(GPE Bean/NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>('Bean', 'NNP'),</td>\n",
       "      <td>Bean: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(PERSON Apple/NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(\"''\", \"''\"),</td>\n",
       "      <td>\": '' (PUNCT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>('and', 'CC'),</td>\n",
       "      <td>and: CC (CCONJ)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>('``', '``'),</td>\n",
       "      <td>\": `` (PUNCT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>('Ice', 'NNP'),</td>\n",
       "      <td>Ice: NNP (PROPN)\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>('Cream', 'NNP'),</td>\n",
       "      <td>Cream: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>('Sandwich', 'NNP'),</td>\n",
       "      <td>Sandwich: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(\"''\", \"''\"),</td>\n",
       "      <td>\": '' (PUNCT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>('operating', 'VBG'),</td>\n",
       "      <td>operating: NN (NOUN)</td>\n",
       "      <td>NLTK tags operating as \"verb, present participle or gerund\", amd SpaCy tags it as  \"noun, singular or mass\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>('systems', 'NNS'),</td>\n",
       "      <td>systems: NNS (NOUN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(',', ','),</td>\n",
       "      <td>,: , (PUNCT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>('which', 'WDT'),</td>\n",
       "      <td>which: WDT (PRON)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>('Apple', 'NNP'),</td>\n",
       "      <td>Apple: NNP (PROPN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>('claims', 'VBZ'),</td>\n",
       "      <td>claims: VBZ (VERB)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>('infringe', 'VB'),</td>\n",
       "      <td>infringe: VBP (VERB)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>('its', 'PRP$'),</td>\n",
       "      <td>its: PRP$ (PRON)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>('patents', 'NNS'),</td>\n",
       "      <td>patents: NNS (NOUN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>('.', '.')],</td>\n",
       "      <td>.: . (PUNCT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NLTK (POS TAGGING)        SpaCy (TOKEN.TAG)  \\\n",
       "0    ('Documents', 'NNS'),  Documents: NNPS (PROPN)   \n",
       "1        ('filed', 'VBN'),        filed: VBD (VERB)   \n",
       "2            ('to', 'TO'),             to: IN (ADP)   \n",
       "3           ('the', 'DT'),            the: DT (DET)   \n",
       "4          ('San', 'NNP'),         San: NNP (PROPN)   \n",
       "5         ('Jose', 'NNP'),        Jose: NNP (PROPN)   \n",
       "6       ('federal', 'JJ'),      federal: JJ (ADJ)\\n   \n",
       "7         ('court', 'NN'),         court: NN (NOUN)   \n",
       "8            ('in', 'IN'),             in: IN (ADP)   \n",
       "9   ('California', 'NNP'),  California: NNP (PROPN)   \n",
       "10           ('on', 'IN'),             on: IN (ADP)   \n",
       "11    ('November', 'NNP'),    November: NNP (PROPN)   \n",
       "12           ('23', 'CD'),             23: CD (NUM)   \n",
       "13         ('list', 'NN'),          list: NN (NOUN)   \n",
       "14          ('six', 'CD'),            six: CD (NUM)   \n",
       "15     ('Samsung', 'NNP'),     Samsung: NNP (PROPN)   \n",
       "16    ('products', 'NNS'),     products: NNS (NOUN)   \n",
       "17     ('running', 'VBG'),    running: VBG (VERB)\\n   \n",
       "18          ('the', 'DT'),            the: DT (DET)   \n",
       "19           ('``', '``'),            \": `` (PUNCT)   \n",
       "20        ('Jelly', 'RB'),       Jelly: NNP (PROPN)   \n",
       "21        ('Bean', 'NNP'),        Bean: NNP (PROPN)   \n",
       "22           (\"''\", \"''\"),            \": '' (PUNCT)   \n",
       "23          ('and', 'CC'),          and: CC (CCONJ)   \n",
       "24           ('``', '``'),            \": `` (PUNCT)   \n",
       "25         ('Ice', 'NNP'),       Ice: NNP (PROPN)\\n   \n",
       "26       ('Cream', 'NNP'),       Cream: NNP (PROPN)   \n",
       "27    ('Sandwich', 'NNP'),    Sandwich: NNP (PROPN)   \n",
       "28           (\"''\", \"''\"),            \": '' (PUNCT)   \n",
       "29   ('operating', 'VBG'),     operating: NN (NOUN)   \n",
       "30     ('systems', 'NNS'),      systems: NNS (NOUN)   \n",
       "31             (',', ','),             ,: , (PUNCT)   \n",
       "32       ('which', 'WDT'),        which: WDT (PRON)   \n",
       "33       ('Apple', 'NNP'),       Apple: NNP (PROPN)   \n",
       "34      ('claims', 'VBZ'),       claims: VBZ (VERB)   \n",
       "35     ('infringe', 'VB'),     infringe: VBP (VERB)   \n",
       "36        ('its', 'PRP$'),         its: PRP$ (PRON)   \n",
       "37     ('patents', 'NNS'),      patents: NNS (NOUN)   \n",
       "38            ('.', '.')],             .: . (PUNCT)   \n",
       "\n",
       "                                                                                                                   Notes  \\\n",
       "0                                                                                                                    NaN   \n",
       "1                                                                                                                    NaN   \n",
       "2   NLTK just tags to as TO, but SpaCy uses IN to tag preposition or subordinating conjunction (e.g., \"to\", \"in\", \"on\")*   \n",
       "3                                                                                                                    NaN   \n",
       "4                                                                                                                    NaN   \n",
       "5                                                                                                                    NaN   \n",
       "6                                                                                                                    NaN   \n",
       "7                                                                                                                    NaN   \n",
       "8                                            NLTK has a seperate IN tag, where SpaCy uses the IN tag for multiple words*   \n",
       "9                                                                                                                    NaN   \n",
       "10                                                                                                                     *   \n",
       "11                                                                                                                   NaN   \n",
       "12                                                                                                                   NaN   \n",
       "13                                                                                                                   NaN   \n",
       "14                                                                                                                   NaN   \n",
       "15                                                                                                                   NaN   \n",
       "16                                                                                                                   NaN   \n",
       "17                                                                                                                   NaN   \n",
       "18                                                                                                                   NaN   \n",
       "19                                                                                                                   NaN   \n",
       "20                                                   NLTK tags jelly as an adverb, SpaCy tags it as proper noun singular   \n",
       "21                                                                                                                   NaN   \n",
       "22                                                                                                                   NaN   \n",
       "23                                                                                                                   NaN   \n",
       "24                                                                                                                   NaN   \n",
       "25                                                                                                                   NaN   \n",
       "26                                                                                                                   NaN   \n",
       "27                                                                                                                   NaN   \n",
       "28                                                                                                                   NaN   \n",
       "29           NLTK tags operating as \"verb, present participle or gerund\", amd SpaCy tags it as  \"noun, singular or mass\"   \n",
       "30                                                                                                                   NaN   \n",
       "31                                                                                                                   NaN   \n",
       "32                                                                                                                   NaN   \n",
       "33                                                                                                                   NaN   \n",
       "34                                                                                                                   NaN   \n",
       "35                                                                                                                   NaN   \n",
       "36                                                                                                                   NaN   \n",
       "37                                                                                                                   NaN   \n",
       "38                                                                                                                   NaN   \n",
       "\n",
       "    Unnamed: 3                                              Unnamed: 4  \n",
       "0          NaN                                                     NaN  \n",
       "1          NaN  * every instance where i noticed the use of the IN tag  \n",
       "2          NaN                                                     NaN  \n",
       "3          NaN                                                   SPACY  \n",
       "4          NaN                  Named Entities, Phrases, and Concepts:  \n",
       "5          NaN                                           San Jose: GPE  \n",
       "6          NaN                                         California: GPE  \n",
       "7          NaN                                       November 23: DATE  \n",
       "8          NaN                                           six: CARDINAL  \n",
       "9          NaN                                            Samsung: ORG  \n",
       "10         NaN                                 Jelly Bean: WORK_OF_ART  \n",
       "11         NaN                                              Apple: ORG  \n",
       "12         NaN                                                     NaN  \n",
       "13         NaN                                                     NaN  \n",
       "14         NaN                                                     NaN  \n",
       "15         NaN                                                     NaN  \n",
       "16         NaN                                                     NaN  \n",
       "17         NaN                         (ORGANIZATION San/NNP Jose/NNP)  \n",
       "18         NaN                                    (GPE California/NNP)  \n",
       "19         NaN                              (ORGANIZATION Samsung/NNP)  \n",
       "20         NaN                                          (GPE Bean/NNP)  \n",
       "21         NaN                                      (PERSON Apple/NNP)  \n",
       "22         NaN                                                     NaN  \n",
       "23         NaN                                                     NaN  \n",
       "24         NaN                                                     NaN  \n",
       "25         NaN                                                     NaN  \n",
       "26         NaN                                                     NaN  \n",
       "27         NaN                                                     NaN  \n",
       "28         NaN                                                     NaN  \n",
       "29         NaN                                                     NaN  \n",
       "30         NaN                                                     NaN  \n",
       "31         NaN                                                     NaN  \n",
       "32         NaN                                                     NaN  \n",
       "33         NaN                                                     NaN  \n",
       "34         NaN                                                     NaN  \n",
       "35         NaN                                                     NaN  \n",
       "36         NaN                                                     NaN  \n",
       "37         NaN                                                     NaN  \n",
       "38         NaN                                                     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_excel(\"Group43_lab1/text_mining_1.xlsx\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
    "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?\n",
    "\n",
    "We looked at the first sentence to compare the outputs from both NLTK and SpaCY for Named Entity Recognition and we believe that SpaCy works better. For example, SpaCy recognized San Jose as a GPE (geopolitical entity) while NLTK recognized it as an organization. NLTK also did not recognize November 23 as a date, while SpaCy did. The two did classify Samsung correctly as an organization. However, both also misclassified Jelly Bean, SpaCy giving us that its a WORK_OF_ART and NLTK recognizing only Bean as a GPE. Lastly, SpaCy classified Apple as an organization while NLTK classified it as a person. Though both are clearly not perfect, we felt that SpaCY made less mistakes overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
    "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n",
    "* describe differences between the output from NLTK and spaCy.\n",
    "\n",
    "Constituency parsing breaks a sentence into hierachical tree of phrases based on grammar rules. It represent the syntactic structure of the sentence by identifying noun phrases, verb phrases and other components. On the other hand, dependency parsing represents a sentence in terms of dependencies between words, showing grammatical relationships. Each word is connected to a headword forming a directed graph. NLTK uses the constituency based approach while spaCy uses a dependency based approach. In the output there are still some differences between the two due to the two different approaches. In 1 NLTK treats it as a plural noun while spaCy as a proper noun plural, in 2 NLTK tags it as past participle while spaCy as a simple past verb, in 3 NLTK tags it as TO while spaCy as ADP which means adposition, in 21 NLTK tags it as an adverb while spaCy as a proper noun and then as last in 30 NLTK tags it as a verb while spaCy as a noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
